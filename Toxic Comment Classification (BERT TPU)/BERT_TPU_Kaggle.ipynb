{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT TPU - Kaggle.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6a54eb507bf0494497977ee30dffccc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a396d360a0ba4cfb8ca5e002fd519d17",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f41693ab450c492fba233a855a7ae2e9",
              "IPY_MODEL_0ae0e794bc2640f69a08cdd3210f6457",
              "IPY_MODEL_a8b73181d1f843e2956f21cbf8b8e76f"
            ]
          }
        },
        "a396d360a0ba4cfb8ca5e002fd519d17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f41693ab450c492fba233a855a7ae2e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a97a5b02e7ca408abf1ace1d6275038a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_082469178ea048aca6c5e98c99061506"
          }
        },
        "0ae0e794bc2640f69a08cdd3210f6457": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_798db46b94e24781bc29bfdd96923f05",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_415ec99ca5aa4e88928c1916f55e62a8"
          }
        },
        "a8b73181d1f843e2956f21cbf8b8e76f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1279829c73cd4f8887efc77bf4aae347",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 12.8kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_930c243a7d1a4011b0ec65bdff06f365"
          }
        },
        "a97a5b02e7ca408abf1ace1d6275038a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "082469178ea048aca6c5e98c99061506": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "798db46b94e24781bc29bfdd96923f05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "415ec99ca5aa4e88928c1916f55e62a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1279829c73cd4f8887efc77bf4aae347": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "930c243a7d1a4011b0ec65bdff06f365": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "15e2a86b19704f3d8e4c3bee89edafb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_30a5c17c7a664ab086d6ac105dd99568",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2e753c09f91c4e239a9e368e2124f910",
              "IPY_MODEL_96a894bc7532426883e063abcb4952a5",
              "IPY_MODEL_9b6d601b94fd47ba8088b9917bd8fc58"
            ]
          }
        },
        "30a5c17c7a664ab086d6ac105dd99568": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2e753c09f91c4e239a9e368e2124f910": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d3315de90d974808911f94b8def99e28",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c5a9d4be4a3f4771b9dd50f2b24482d7"
          }
        },
        "96a894bc7532426883e063abcb4952a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_49025d78a2fb4df8a0decf49a5c73815",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 536063208,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 536063208,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_41ae022562974b7897c09051c0e3089d"
          }
        },
        "9b6d601b94fd47ba8088b9917bd8fc58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_44e730f67c8142dfb9fb84beb3c6a008",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 511M/511M [00:15&lt;00:00, 38.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_080676ff1f774441868eb24db7ce6e62"
          }
        },
        "d3315de90d974808911f94b8def99e28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c5a9d4be4a3f4771b9dd50f2b24482d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "49025d78a2fb4df8a0decf49a5c73815": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "41ae022562974b7897c09051c0e3089d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "44e730f67c8142dfb9fb84beb3c6a008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "080676ff1f774441868eb24db7ce6e62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f-Mvny--cGn"
      },
      "source": [
        "# The Problem\n",
        "\n",
        "Discussing things you care about can be difficult. The threat of abuse and harassment online means that many people stop expressing themselves and give up on seeking different opinions. Platforms struggle to effectively facilitate conversations, leading many communities to limit or completely shut down user comments.\n",
        "\n",
        "In Toxic Comment Challenge competition held on Kaggle, the challenge was to build a multi-headed model that’s capable of detecting different types of of toxicity like threats, obscenity, insults, and identity-based hate.\n",
        "\n",
        "*Credits: https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZIemfzirMw-"
      },
      "source": [
        "# Import Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGqqD0-yriGD",
        "outputId": "d345543f-4594-4be8-8810-08e439f2f1cc"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 53.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Collecting huggingface-hub>=0.0.17\n",
            "  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 30.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 57.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.19 pyyaml-5.4.1 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5aIXT-OrMJP"
      },
      "source": [
        "import tensorflow as tf\n",
        "import logging\n",
        "from tensorflow.keras.layers import (\n",
        "    Dense,\n",
        "    Flatten,\n",
        "    Conv1D,\n",
        "    Dropout,\n",
        "    Input,\n",
        "    GlobalAveragePooling1D\n",
        ")\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import regularizers\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "from tensorflow.keras.callbacks import History, EarlyStopping, ModelCheckpoint\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "\n",
        "# Load Huggingface transformers\n",
        "from transformers import TFBertModel,  BertConfig, BertTokenizerFast, TFAutoModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4oHNFcsrV8j"
      },
      "source": [
        "# Check For TPU Availability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kubx6VMwrXFE",
        "outputId": "53c733d3-b713-48a2-9bd6-d72c8263dcbd"
      },
      "source": [
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "except ValueError:\n",
        "    strategy = tf.distribute.get_strategy() # for CPU and single GPU\n",
        "    print('Number of replicas:', strategy.num_replicas_in_sync)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.33.6.138:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.33.6.138:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhscjruMraJ2"
      },
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "Do a simple data cleaning to lowercase text, split up contractions and replace some toxic words that were written together without spacing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcZydlO_cRNG",
        "outputId": "62168533-946b-4092-c84e-bba3cc5d9dd3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TV0le10Zrch7"
      },
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "\n",
        "    # Split up contractions\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"can't\", \"cannot \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
        "    text = re.sub('\\W', ' ', text)\n",
        "    text = re.sub('\\s+', ' ', text)\n",
        "    text = text.strip(' ')\n",
        "\n",
        "    # Split up toxic words\n",
        "    toxic_reference_dictionary = {\"youfuck\": \"you fuck\", \n",
        "                                  \"fucksex\": \"fuck sex\",\n",
        "                                  \"bitchbot\": \"bitch bot\",\n",
        "                                  \"offfuck\": \"fuck off\",\n",
        "                                  \"donkeysex\": \"donkey sex\",\n",
        "                                  \"securityfuck\": \"security fuck\",\n",
        "                                  \"ancestryfuck\": \"ancestry fuck\",\n",
        "                                  \"turkeyfuck\": \"turkey fuck\",\n",
        "                                  \"faggotgay\": \"faggot gay\",\n",
        "                                  \"fuckbot\": \"fuck bot\",\n",
        "                                  \"assfuckers\": \"ass fucker\",\n",
        "                                  \"ckckck\": \"cock\",\n",
        "                                  \"fuckfuck\": \"fuck\",\n",
        "                                  \"lolol\": \"lol\",\n",
        "                                  \"pussyfuck\": \"pussy fuck\",\n",
        "                                  \"gaygay\": \"gay\",\n",
        "                                  \"haha\": \"ha\",\n",
        "                                  \"sucksuck\": \"suck\"\n",
        "                                  }\n",
        "    for existing,new_word in toxic_reference_dictionary.items():\n",
        "        text = text.replace(existing,new_word)\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjkQ0lW1R6jF"
      },
      "source": [
        "train_df = pd.read_csv(\"./train.csv\").fillna(\"blank\")\n",
        "test_df = pd.read_csv(\"./test.csv\").fillna(\"blank\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dqjk1hwKrgrI"
      },
      "source": [
        "train_df['comment_text'] = train_df['comment_text'].map(lambda x : clean_text(x))\n",
        "test_df['comment_text'] = test_df['comment_text'].map(lambda x : clean_text(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdK_u3GURJft"
      },
      "source": [
        "## Handling Class Imbalance\n",
        "\n",
        "There are many approaches that we can apply but they generally fall within 2 major school-of-thoughts:\n",
        "1. Sampling (ROSE, SMOTE, etc)\n",
        "2. Class weighting\n",
        "\n",
        "### Bigger problems to solve.....\n",
        "While it is nice if we can try out all the techniques, it is unlikely that most of us have sufficient computation resources to do it. \n",
        "\n",
        "### Solution:\n",
        "Due to limited computation time on Colab's free tier, I will only use the simplest method of sampling which is to balance out the number of clean and toxic comments relatively evenly. Surprisingly, this is sufficient to give us a reasonable baseline model!\n",
        "\n",
        "\n",
        "|S/N:| Method | Description |\n",
        "|--- | --- | --- |\n",
        "|1| Simple Sampling | Sample 20,000 clean comments but extract **ALL** toxic comments. |\n",
        "|2|ROSE| Naive strategy is to generate new samples by randomly sampling with replacement the current available samples\n",
        "|3|SMOTE| Generate new samples in by interpolation\n",
        "|4|Class Weights Adjustments (Manual)| Create a new column to classify between Toxic VS Clean comments and assign weights with formula: `(1/class) * (total/2.0)`|\n",
        "|5|Class Weights Adjustments (Sklearn)| Use Sklearn class weight computation to automatically assign weights|\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aYZ8uQhRLmr"
      },
      "source": [
        "# Split dataset into toxic and clean comments\n",
        "LABEL_COLUMNS = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "train_toxic = train_df[train_df[LABEL_COLUMNS].sum(axis=1) > 0]\n",
        "train_clean = train_df[train_df[LABEL_COLUMNS].sum(axis=1) == 0]\n",
        "\n",
        "# Sampling toxic and clean comments dataset\n",
        "final_training_df = pd.concat([\n",
        "  train_toxic,\n",
        "  train_clean.sample(20000)\n",
        "])\n",
        "\n",
        "# Shuffle dataset\n",
        "final_training_df = final_training_df.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUNQbWVUrsH5"
      },
      "source": [
        "# from sklearn.utils import class_weight\n",
        "\n",
        "# class_weights = class_weight.compute_class_weight('balanced',\n",
        "#                                                  np.unique(train_df[LABEL_COLUMNS]),\n",
        "#                                                  train_df[LABEL_COLUMNS])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FJa1D4vVslH"
      },
      "source": [
        "## Encode Data & Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466,
          "referenced_widgets": [
            "6a54eb507bf0494497977ee30dffccc5",
            "a396d360a0ba4cfb8ca5e002fd519d17",
            "f41693ab450c492fba233a855a7ae2e9",
            "0ae0e794bc2640f69a08cdd3210f6457",
            "a8b73181d1f843e2956f21cbf8b8e76f",
            "a97a5b02e7ca408abf1ace1d6275038a",
            "082469178ea048aca6c5e98c99061506",
            "798db46b94e24781bc29bfdd96923f05",
            "415ec99ca5aa4e88928c1916f55e62a8",
            "1279829c73cd4f8887efc77bf4aae347",
            "930c243a7d1a4011b0ec65bdff06f365",
            "e7afe843f323460e975a909e8f83d425",
            "ba0f0dbe5c6f44f5b110949d1d1f798a",
            "76c658a093d642c0b3cc23f344431b1d"
          ]
        },
        "id": "LBODP4PNtzEX",
        "outputId": "cf99f91b-26fc-4e3b-efba-1cbd42349e94"
      },
      "source": [
        "# Name of the BERT model to use\n",
        "model_name = 'bert-base-uncased'\n",
        "\n",
        "# Max length of tokens\n",
        "max_length = 512\n",
        "\n",
        "# Load transformers config and set output_hidden_states to False\n",
        "config = BertConfig.from_pretrained(model_name)\n",
        "#config.output_hidden_states = False\n",
        "\n",
        "# Load BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(pretrained_model_name_or_path = model_name, config = config)\n",
        "\n",
        "def bert_encode(data):\n",
        "    tokens = tokenizer.batch_encode_plus(\n",
        "        data,\n",
        "        add_special_tokens=True,\n",
        "        max_length=max_length,\n",
        "        truncation=True,\n",
        "        padding=True, \n",
        "        return_tensors='tf',\n",
        "        return_token_type_ids = False,\n",
        "        return_attention_mask = True,\n",
        "        verbose = True\n",
        "    )\n",
        "    return tf.constant(tokens[\"input_ids\"])\n",
        "\n",
        "# Split into training and validation dataset\n",
        "training_dataset, val_dataset = train_test_split(final_training_df, test_size=0.1, random_state=42)\n",
        "\n",
        "# Encode training and validation dataset - FEATURES\n",
        "train_encoded = bert_encode(training_dataset.comment_text)\n",
        "val_encoded = bert_encode(val_dataset.comment_text)\n",
        "\n",
        "# Encode training and validation dataset - LABELS\n",
        "train_labels=training_dataset[LABEL_COLUMNS].values\n",
        "train_labels=train_labels.reshape(-1,len(LABEL_COLUMNS))\n",
        "\n",
        "val_labels=val_dataset[LABEL_COLUMNS].values\n",
        "val_labels=val_labels.reshape(-1,len(LABEL_COLUMNS))\n",
        "\n",
        "print()\n",
        "print(f'Train labels shape: {train_labels.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to acquire lock 139848561624976 on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n",
            "DEBUG:filelock:Lock 139848561624976 acquired on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a54eb507bf0494497977ee30dffccc5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 139848561624976 on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n",
            "DEBUG:filelock:Lock 139848561624976 released on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 139847743771856 on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
            "DEBUG:filelock:Lock 139847743771856 acquired on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7afe843f323460e975a909e8f83d425",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 139847743771856 on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
            "DEBUG:filelock:Lock 139847743771856 released on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 139847694924816 on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
            "DEBUG:filelock:Lock 139847694924816 acquired on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba0f0dbe5c6f44f5b110949d1d1f798a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 139847694924816 on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
            "DEBUG:filelock:Lock 139847694924816 released on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
            "DEBUG:filelock:Attempting to acquire lock 139848559278160 on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
            "DEBUG:filelock:Lock 139848559278160 acquired on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76c658a093d642c0b3cc23f344431b1d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 139848559278160 on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
            "DEBUG:filelock:Lock 139848559278160 released on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32602, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4hWhxJohlR0"
      },
      "source": [
        "# Fitting into a Tensor unit\n",
        "train_dataset = (\n",
        "    tf.data.Dataset.from_tensor_slices((train_encoded, train_labels))\n",
        "    .shuffle(100)\n",
        "    .batch(32)\n",
        ").cache()\n",
        "\n",
        "val_dataset = (\n",
        "    tf.data.Dataset.from_tensor_slices((val_encoded, val_labels))\n",
        "    .shuffle(100)\n",
        "    .batch(32)\n",
        ").cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOPftKF3t0nG"
      },
      "source": [
        "# Create BERT Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itHhAKHbV3NK"
      },
      "source": [
        "def bert_tpu_model():\n",
        "    \n",
        "    # ========================================================\n",
        "    # Results - 98.341% testing accuracy\n",
        "    bert_encoder = TFAutoModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    input_ids = Input(shape=(max_length,), name='input_ids', dtype='int32')\n",
        "\n",
        "    last_hidden_states = bert_encoder(input_ids)[0]\n",
        "\n",
        "    clf_output = Flatten()(last_hidden_states)\n",
        "\n",
        "    dense_01 = Dense(512, activation='relu', name='dense_01')(clf_output)\n",
        "    dropout_01 = Dropout(0.5)(dense_01)\n",
        "\n",
        "    dense_02 = Dense(512, activation='relu', name='dense_02')(dropout_01)\n",
        "    dropout_02 = Dropout(0.5)(dense_02)\n",
        "\n",
        "    out =Dense(6, activation='sigmoid', name='outputs')(dropout_02)\n",
        "\n",
        "    model = Model(inputs=input_ids, outputs=out)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655,
          "referenced_widgets": [
            "15e2a86b19704f3d8e4c3bee89edafb2",
            "30a5c17c7a664ab086d6ac105dd99568",
            "2e753c09f91c4e239a9e368e2124f910",
            "96a894bc7532426883e063abcb4952a5",
            "9b6d601b94fd47ba8088b9917bd8fc58",
            "d3315de90d974808911f94b8def99e28",
            "c5a9d4be4a3f4771b9dd50f2b24482d7",
            "49025d78a2fb4df8a0decf49a5c73815",
            "41ae022562974b7897c09051c0e3089d",
            "44e730f67c8142dfb9fb84beb3c6a008",
            "080676ff1f774441868eb24db7ce6e62"
          ]
        },
        "id": "BbJh39DiWeC-",
        "outputId": "fc533334-cb0b-4ea0-fa30-199bc5be1f1e"
      },
      "source": [
        "with strategy.scope():\n",
        "    model = bert_tpu_model()\n",
        "    optimizer = Adam(learning_rate=1e-5, decay=1e-6)\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                    optimizer=optimizer,\n",
        "                    metrics=['accuracy'])\n",
        "    model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to acquire lock 139847654062736 on /root/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5.lock\n",
            "DEBUG:filelock:Lock 139847654062736 acquired on /root/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "15e2a86b19704f3d8e4c3bee89edafb2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/511M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 139847654062736 on /root/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5.lock\n",
            "DEBUG:filelock:Lock 139847654062736 released on /root/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5.lock\n",
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_ids (InputLayer)       [(None, 512)]             0         \n",
            "_________________________________________________________________\n",
            "tf_bert_model (TFBertModel)  TFBaseModelOutputWithPool 109482240 \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 393216)            0         \n",
            "_________________________________________________________________\n",
            "dense_01 (Dense)             (None, 512)               201327104 \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_02 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_38 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "outputs (Dense)              (None, 6)                 3078      \n",
            "=================================================================\n",
            "Total params: 311,075,078\n",
            "Trainable params: 311,075,078\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9kH9IOsY-Wm",
        "outputId": "3b6ca3e7-75c9-41f0-9f18-73a3d02eae12"
      },
      "source": [
        "history = History()\n",
        "\n",
        "# Set early stopping\n",
        "es = EarlyStopping(monitor='val_accuracy', \n",
        "                   mode='max', \n",
        "                   verbose=1, \n",
        "                   patience=8)  # Training will wait 8 epochs to check for any improvement to validation accuracy\n",
        "\n",
        "# Save best model to train epoch\n",
        "checkpoint = ModelCheckpoint('./bert_sampling_wgts.hdf5', \n",
        "                             monitor='val_accuracy',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True,\n",
        "                             save_weights_only=True, \n",
        "                             mode='max');  \n",
        "\n",
        "callbacks = [es, checkpoint, history]\n",
        "\n",
        "model.fit(\n",
        "    train_dataset,\n",
        "    batch_size=32,\n",
        "    epochs=100,\n",
        "    validation_data=val_dataset,\n",
        "    verbose=1,\n",
        "    callbacks=callbacks\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 6) dtype=int64>]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 6) dtype=int64>]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1019/1019 [==============================] - ETA: 0s - loss: 0.2327 - accuracy: 0.5534"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 6) dtype=int64>]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1019/1019 [==============================] - 321s 230ms/step - loss: 0.2327 - accuracy: 0.5534 - val_loss: 0.1524 - val_accuracy: 0.7047\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.70466, saving model to /content/drive/MyDrive/Colab Notebooks/bert_sampling_wgts.hdf5\n",
            "Epoch 2/100\n",
            "1019/1019 [==============================] - 218s 214ms/step - loss: 0.1669 - accuracy: 0.5914 - val_loss: 0.1493 - val_accuracy: 0.7560\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.70466 to 0.75600, saving model to /content/drive/MyDrive/Colab Notebooks/bert_sampling_wgts.hdf5\n",
            "Epoch 3/100\n",
            "1019/1019 [==============================] - 218s 214ms/step - loss: 0.1490 - accuracy: 0.6270 - val_loss: 0.1374 - val_accuracy: 0.8366\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.75600 to 0.83660, saving model to /content/drive/MyDrive/Colab Notebooks/bert_sampling_wgts.hdf5\n",
            "Epoch 4/100\n",
            "1019/1019 [==============================] - 218s 214ms/step - loss: 0.1346 - accuracy: 0.6402 - val_loss: 0.1431 - val_accuracy: 0.9081\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.83660 to 0.90809, saving model to /content/drive/MyDrive/Colab Notebooks/bert_sampling_wgts.hdf5\n",
            "Epoch 5/100\n",
            "1019/1019 [==============================] - 219s 215ms/step - loss: 0.1243 - accuracy: 0.6749 - val_loss: 0.1462 - val_accuracy: 0.9365\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.90809 to 0.93652, saving model to /content/drive/MyDrive/Colab Notebooks/bert_sampling_wgts.hdf5\n",
            "Epoch 6/100\n",
            "1019/1019 [==============================] - 219s 215ms/step - loss: 0.1123 - accuracy: 0.6823 - val_loss: 0.1421 - val_accuracy: 0.8984\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.93652\n",
            "Epoch 7/100\n",
            "1019/1019 [==============================] - 218s 214ms/step - loss: 0.1028 - accuracy: 0.7000 - val_loss: 0.1545 - val_accuracy: 0.9034\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.93652\n",
            "Epoch 8/100\n",
            "1019/1019 [==============================] - 218s 214ms/step - loss: 0.0918 - accuracy: 0.7109 - val_loss: 0.1662 - val_accuracy: 0.8606\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.93652\n",
            "Epoch 9/100\n",
            "1019/1019 [==============================] - 218s 214ms/step - loss: 0.0827 - accuracy: 0.6862 - val_loss: 0.1661 - val_accuracy: 0.8156\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.93652\n",
            "Epoch 10/100\n",
            "1019/1019 [==============================] - 218s 214ms/step - loss: 0.0737 - accuracy: 0.7089 - val_loss: 0.1865 - val_accuracy: 0.8868\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.93652\n",
            "Epoch 11/100\n",
            "1019/1019 [==============================] - 218s 214ms/step - loss: 0.0663 - accuracy: 0.7049 - val_loss: 0.1870 - val_accuracy: 0.8178\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.93652\n",
            "Epoch 12/100\n",
            "1019/1019 [==============================] - 218s 214ms/step - loss: 0.0590 - accuracy: 0.7190 - val_loss: 0.2221 - val_accuracy: 0.8786\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.93652\n",
            "Epoch 13/100\n",
            "1019/1019 [==============================] - 218s 213ms/step - loss: 0.0530 - accuracy: 0.7178 - val_loss: 0.2332 - val_accuracy: 0.9136\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.93652\n",
            "Epoch 00013: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f30ceea3210>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQoFe0M_Y-pJ"
      },
      "source": [
        "# test_encoded = bert_encode(test_df.comment_text)\n",
        "\n",
        "# # test_dataset = (\n",
        "# #     tf.data.Dataset.from_tensor_slices((test_encoded))\n",
        "# #     .shuffle(100)\n",
        "# #     .batch(64)\n",
        "# # ).cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvF0cooxr3d7"
      },
      "source": [
        "# predictions = model.predict(test_encoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ut_j5TB0Jb4u"
      },
      "source": [
        "# final_df=pd.DataFrame(predictions,columns=list_classes)\n",
        "# final_df['id'] = test_df['id']\n",
        "# final_df=final_df[['id']+(list_classes)]\n",
        "# final_df[\"comment_text\"] = test_df['comment_text']\n",
        "# final_df"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}