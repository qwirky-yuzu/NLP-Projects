{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Training_seq2seq_pytorch.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Afzoe8pTPpAy"},"source":["# **Import Libraries**"]},{"cell_type":"code","metadata":{"id":"HTRASOhn2ZSK"},"source":["import pandas as pd\n","from __future__ import absolute_import, division, print_function, unicode_literals\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","from torch.jit import script, trace\n","import torch.nn.functional as F\n","import csv\n","import random\n","\n","import re\n","import os\n","import unicodedata\n","import codecs\n","from io import open\n","import itertools\n","import math"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5aIF6gQk_b5Q"},"source":["# **Mount Drive & Redirect to local directory**"]},{"cell_type":"code","metadata":{"id":"PHOyklnWsBKU"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WzNlQ1bFP786"},"source":["# **Read Data**"]},{"cell_type":"code","metadata":{"id":"vSfU-f9J_baR","colab":{"base_uri":"https://localhost:8080/","height":355},"outputId":"0128af64-ff82-45b8-ea26-3d9e6c2fe62a"},"source":["# View dataframe\n","southpark_df = pd.read_csv(\"All-seasons - Copy.csv\")\n","southpark_df.head(10)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Season</th>\n","      <th>Episode</th>\n","      <th>Character</th>\n","      <th>Line</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Boys</td>\n","      <td>School day, school day, teacher's golden ru...\\n</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Kyle</td>\n","      <td>Ah, damn it! My little brother's trying to fol...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Ike</td>\n","      <td>Zeeponanner.\\n</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Kyle</td>\n","      <td>Ike, you can't come to school with me. \\n</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cartman</td>\n","      <td>Yeah, go home you little dildo.\\n</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Kyle</td>\n","      <td>Dude, don't call my brother a dildo!\\n</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Stan</td>\n","      <td>What's a dildo?\\n</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Kyle</td>\n","      <td>Well, I don't know...  and I'll bet Cartman do...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cartman</td>\n","      <td>I know what it means!\\n</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Kyle</td>\n","      <td>Well, what?\\n</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Season  Episode Character                                               Line\n","0       1        1      Boys   School day, school day, teacher's golden ru...\\n\n","1       1        1      Kyle  Ah, damn it! My little brother's trying to fol...\n","2       1        1       Ike                                     Zeeponanner.\\n\n","3       1        1      Kyle          Ike, you can't come to school with me. \\n\n","4       1        1   Cartman                  Yeah, go home you little dildo.\\n\n","5       1        1      Kyle             Dude, don't call my brother a dildo!\\n\n","6       1        1      Stan                                  What's a dildo?\\n\n","7       1        1      Kyle  Well, I don't know...  and I'll bet Cartman do...\n","8       1        1   Cartman                            I know what it means!\\n\n","9       1        1      Kyle                                      Well, what?\\n"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"gyFUt7kr_bc3","colab":{"base_uri":"https://localhost:8080/","height":295},"outputId":"041171a9-07f5-4477-936e-54e2d599828a"},"source":["# View first few lines\n","print(\"South Park lines:\")\n","for i in range(0,5):\n","    print(\"Line #\",i+1)\n","    print(southpark_df.Line[i])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["South Park lines:\n","Line # 1\n","School day, school day, teacher's golden ru...\n","\n","Line # 2\n","Ah, damn it! My little brother's trying to follow me to school again.\n","\n","Line # 3\n","Zeeponanner.\n","\n","Line # 4\n","Ike, you can't come to school with me. \n","\n","Line # 5\n","Yeah, go home you little dildo.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BlN830CgQVs9"},"source":["# **Data Preprocessing**"]},{"cell_type":"markdown","metadata":{"id":"9GadWDuYQZ4U"},"source":["#### **Find number of seasons**"]},{"cell_type":"code","metadata":{"id":"4iZD4yaZDIoF","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"ad0e28ad-1d05-45e5-d97c-a5ac2ad3d267"},"source":["# Find number of seasons\n","seasons_list = southpark_df[\"Season\"].tolist()\n","s_list = []\n","for season in seasons_list:\n","  try:\n","    s_int = int(season)\n","    s_list.append(s_int)\n","  except:\n","    pass\n","season_set = set(s_list)\n","print(season_set)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UGfxK0awQdvA"},"source":["#### **Find where each episode index end in Dataframe per season**"]},{"cell_type":"code","metadata":{"id":"n1GCPPNZGuIB"},"source":["# Find where ep_index end per season\n","ep_per_season = [13,18,17,17,14,17,15,14,14,14,14,14,14,14,14,14,10,10]\n","seasons_dictionary = {\"season_1\":{}, \n","                      \"season_2\":{}, \n","                      \"season_3\":{}, \n","                      \"season_4\":{}, \n","                      \"season_5\":{}, \n","                      \"season_6\":{}, \n","                      \"season_7\":{}, \n","                      \"season_8\":{}, \n","                      \"season_9\":{}, \n","                      \"season_10\":{}, \n","                      \"season_11\":{}, \n","                      \"season_12\":{}, \n","                      \"season_13\":{}, \n","                      \"season_14\":{}, \n","                      \"season_15\":{}, \n","                      \"season_16\":{}, \n","                      \"season_17\":{}, \n","                      \"season_18\":{}}\n","\n","count_index = 0\n","prev_season = 0\n","for a_season in range(1,19):\n","  curr_season = \"season_\" + str(a_season)\n","  total_eps_for_season = ep_per_season[a_season-1]\n","\n","  for an_ep in range(1,total_eps_for_season):\n","    for i in range(len(southpark_df[\"Season\"])):\n","      if int(southpark_df[\"Season\"][i]) > prev_season:\n","        if int(southpark_df[\"Season\"][i]) == a_season and int(southpark_df[\"Episode\"][i]) == an_ep:\n","          count_index += 1\n","        elif int(southpark_df[\"Season\"][i]) != a_season and int(southpark_df[\"Episode\"][i]) != an_ep:\n","          break\n","\n","    sub_dictionary = seasons_dictionary[curr_season]\n","    sub_dictionary[an_ep] = count_index\n","  prev_season = a_season"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bJv3f-jCNZ1g","colab":{"base_uri":"https://localhost:8080/","height":55},"outputId":"259b9dab-0231-4afa-9ef7-f9907e637af6"},"source":["# print(seasons_dictionary)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'season_1': {1: 391, 2: 688, 3: 974, 4: 1338, 5: 1652, 6: 2001, 7: 2338, 8: 2617, 9: 2912, 10: 3222, 11: 3553, 12: 3867}, 'season_2': {1: 4205, 2: 4537, 3: 4832, 4: 5193, 5: 5506, 6: 5835, 7: 6187, 8: 6503, 9: 6839, 10: 7233, 11: 7593, 12: 8037, 13: 8400, 14: 8745, 15: 9096, 16: 9506, 17: 9886}, 'season_3': {1: 10213, 2: 10583, 3: 10971, 4: 11329, 5: 11747, 6: 12055, 7: 12336, 8: 12695, 9: 12984, 10: 13369, 11: 13680, 12: 14055, 13: 14399, 14: 14747, 15: 15061, 16: 15344}, 'season_4': {1: 15703, 2: 16076, 3: 16431, 4: 16777, 5: 17043, 6: 17378, 7: 17703, 8: 18025, 9: 18385, 10: 18735, 11: 19102, 12: 19442, 13: 19752, 14: 20025, 15: 20367, 16: 20690}, 'season_5': {1: 21036, 2: 21315, 3: 21648, 4: 21977, 5: 22312, 6: 22591, 7: 22909, 8: 23270, 9: 23584, 10: 23899, 11: 24225, 12: 24574, 13: 24820}, 'season_6': {1: 25175, 2: 25464, 3: 25796, 4: 26178, 5: 26482, 6: 26698, 7: 26989, 8: 27235, 9: 27536, 10: 27902, 11: 28143, 12: 28416, 13: 28757, 14: 29039, 15: 29368, 16: 29679}, 'season_7': {1: 30017, 2: 30280, 3: 30590, 4: 30845, 5: 31101, 6: 31423, 7: 31680, 8: 32011, 9: 32261, 10: 32524, 11: 32770, 12: 33094, 13: 33327, 14: 33615}, 'season_8': {1: 33907, 2: 34120, 3: 34387, 4: 34662, 5: 34923, 6: 35194, 7: 35389, 8: 35655, 9: 35899, 10: 36180, 11: 36416, 12: 36684, 13: 36925}, 'season_9': {1: 37158, 2: 37409, 3: 37682, 4: 37918, 5: 38206, 6: 38471, 7: 38702, 8: 38962, 9: 39216, 10: 39446, 11: 39681, 12: 39938, 13: 40208}, 'season_10': {1: 40481, 2: 40744, 3: 40948, 4: 41185, 5: 41433, 6: 41666, 7: 41955, 8: 42238, 9: 42451, 10: 42738, 11: 42988, 12: 43224, 13: 43485}, 'season_11': {1: 43707, 2: 43974, 3: 44203, 4: 44530, 5: 44769, 6: 45035, 7: 45309, 8: 45553, 9: 45777, 10: 45980, 11: 46237, 12: 46495, 13: 46730}, 'season_12': {1: 46979, 2: 47201, 3: 47369, 4: 47585, 5: 47787, 6: 48018, 7: 48311, 8: 48564, 9: 48793, 10: 49044, 11: 49274, 12: 49523, 13: 49804}, 'season_13': {1: 50076, 2: 50290, 3: 50486, 4: 50730, 5: 50969, 6: 51196, 7: 51409, 8: 51645, 9: 51882, 10: 52179, 11: 52386, 12: 52596, 13: 52800}, 'season_14': {1: 53017, 2: 53251, 3: 53486, 4: 53733, 5: 54010, 6: 54254, 7: 54465, 8: 54703, 9: 54946, 10: 55271, 11: 55525, 12: 55721, 13: 55911}, 'season_15': {1: 56172, 2: 56365, 3: 56514, 4: 56739, 5: 56953, 6: 57167, 7: 57411, 8: 57641, 9: 57832, 10: 58094, 11: 58357, 12: 58561, 13: 58787}, 'season_16': {1: 59012, 2: 59197, 3: 59435, 4: 59635, 5: 59848, 6: 60102, 7: 60359, 8: 60571, 9: 60745, 10: 60992, 11: 61191, 12: 61443, 13: 61661}, 'season_17': {1: 61867, 2: 62100, 3: 62357, 4: 62626, 5: 62861, 6: 63092, 7: 63300, 8: 63517, 9: 63751}, 'season_18': {1: 63976, 2: 64267, 3: 64469, 4: 64701, 5: 64938, 6: 65178, 7: 65483, 8: 65733, 9: 65983}}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_yv860lOE_Wv"},"source":["import pickle\n","\n","# Store pickle\n","# pickle_out = open(\"/content/drive/My Drive/season_ep_index.pickle\",\"wb\")\n","# pickle.dump(seasons_dictionary, pickle_out)\n","# pickle_out.close()\n","\n","# Open pickle\n","pickle_in = open(\"season_ep_index.pickle\",\"rb\")\n","seasons_dictionary = pickle.load(pickle_in)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ww-BxOhC_qZK"},"source":["#### **Creating a reformatted data corpus**"]},{"cell_type":"code","metadata":{"id":"6Ef54Qo-_s8z"},"source":["def clean_text(text):\n","    '''Clean text by removing unnecessary characters and altering \n","    the format of words. We will do force expansion on some words and\n","    transform some of them to root form'''\n","\n","    # Lowercase\n","    text = text.lower()\n","    \n","    # Substitute text\n","    text = re.sub(r\"\\n\", \"\",  text)\n","    text = re.sub(r\"[-()]\", \"\", text)\n","    text = re.sub(r\"\\.\", \" .\", text)\n","    text = re.sub(r\"\\!\", \" !\", text)\n","    text = re.sub(r\"\\?\", \" ?\", text)\n","    text = re.sub(r\"\\,\", \" ,\", text)\n","\n","    # Force expansion\n","    text = re.sub(r\"i'm\", \"i am\", text)\n","    text = re.sub(r\"he's\", \"he is\", text)\n","    text = re.sub(r\"she's\", \"she is\", text)\n","    text = re.sub(r\"it's\", \"it is\", text)\n","    text = re.sub(r\"that's\", \"that is\", text)\n","    text = re.sub(r\"what's\", \"that is\", text)\n","    text = re.sub(r\"\\'ll\", \" will\", text)\n","    text = re.sub(r\"\\'re\", \" are\", text)\n","    text = re.sub(r\"won't\", \"will not\", text)\n","    text = re.sub(r\"can't\", \"cannot\", text)\n","    text = re.sub(r\"n't\", \" not\", text)\n","    text = re.sub(r\"n'\", \"ng\", text)\n","\n","    # Root word transformation\n","    text = re.sub(r\"ohh\", \"oh\", text)\n","    text = re.sub(r\"ohhh\", \"oh\", text)\n","    text = re.sub(r\"ohhhh\", \"oh\", text)\n","    text = re.sub(r\"ohhhhh\", \"oh\", text)\n","    text = re.sub(r\"ohhhhhh\", \"oh\", text)\n","    text = re.sub(r\"ahh\", \"ah\", text)\n","    \n","    return text\n","\n","def extractSentencePairs(conversations):\n","  \"\"\"\n","  1 conversation = 1 episode of 1 season\n","  conversations = ALL eps in that season\n","\n","\n","  Iterate over all the lines of the conversation\n","  The final line of the conversation would be unable to find a pair hence it \n","  would be ignored.\n","  \"\"\"\n","  qa_pairs = []\n","  for conversation in conversations:\n","      for i in range(len(conversation)-1):\n","          inputLine = conversation[i].strip()\n","          targetLine = conversation[i+1].strip() + \" \\r\"\n","          if inputLine and targetLine:\n","              qa_pairs.append([inputLine, targetLine])\n","  return qa_pairs\n","\n","def printLines(file, n=10):\n","    with open(file, 'rb') as datafile:\n","        lines = datafile.readlines()\n","    for line in lines[:n]:\n","        print(line)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PE3wXRwoyQV1"},"source":["# Get ALL seasons of data \n","conversations = []\n","start_index = 0\n","for a_key in seasons_dictionary:\n","  index_dictionary = seasons_dictionary[a_key]\n","\n","  for ep_key in index_dictionary:\n","    ep_end_index = index_dictionary[ep_key]\n","    conversation = []\n","    for i in range(start_index,ep_end_index):\n","      line = southpark_df[\"Line\"][i]\n","      # Level 1 preprocessing - basic data processing\n","      line = clean_text(line)\n","      conversation.append(line)\n","    start_index = ep_end_index\n","    conversations.append(conversation)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GMucxPWn_tB-","colab":{"base_uri":"https://localhost:8080/","height":260},"outputId":"5e959812-2f09-404c-ec59-d7ee5cb8bede"},"source":["corpus_name = \"southpark_corpus\"\n","new_path = os.path.join(corpus_name, \"formatted_southpark_lines_v2.txt\")\n","delimiter = '\\t'\n","delimiter = str(codecs.decode(delimiter, \"unicode_escape\"))\n","\n","print(\"\\n Writing conversation pairs to new file\")\n","with open(new_path, 'w', encoding = 'utf-8') as outfile:\n","    writer = csv.writer(outfile, delimiter=delimiter, lineterminator = '\\n')\n","    for pair in extractSentencePairs(conversations):\n","        writer.writerow(pair)\n","\n","print(\"\\nSample lines from file:\")\n","printLines(new_path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n"," Writing conversation pairs to new file\n","\n","Sample lines from file:\n","b\"school day , school day , teacher's golden ru . . .\\tah , damn it ! my little brother's trying to follow me to school again . \\r\\n\"\n","b\"ah , damn it ! my little brother's trying to follow me to school again .\\tzeeponanner . \\r\\n\"\n","b'zeeponanner .\\tike , you cannot come to school with me . \\r\\n'\n","b'ike , you cannot come to school with me .\\tyeah , go home you little dildo . \\r\\n'\n","b'yeah , go home you little dildo .\\tdude , do not call my brother a dildo ! \\r\\n'\n","b'dude , do not call my brother a dildo !\\tthat is a dildo ? \\r\\n'\n","b'that is a dildo ?\\twell , i do not know . . .  and i will bet cartman does not know either ! \\r\\n'\n","b'well , i do not know . . .  and i will bet cartman does not know either !\\ti know what it means ! \\r\\n'\n","b'i know what it means !\\twell , what ? \\r\\n'\n","b'well , what ?\\ti am not telling you . \\r\\n'\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VY6x-tDxcEEU"},"source":["#### **Load and Trim data**"]},{"cell_type":"code","metadata":{"id":"ytCLskil_tHA"},"source":["PAD_token = 0 # pad short sentences\n","SOS_token = 1 # sentence start token\n","EOS_token = 2 # sentence end token\n","\n","class Voc:\n","  def __init__(self, name):\n","    self.name = name\n","    self.trimmed = False\n","    self.word2index  = {}\n","    self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n","    self.word2count = {}\n","    self.num_words = 3 \n","  \n","  def addSentences(self, sentence):\n","    for word in sentence.split(' '):\n","      self.addWord(word)\n","\n","  def addWord(self, word):\n","    if word not in self.word2index:\n","      self.word2index[word] = self.num_words\n","      self.word2count[word] = 1\n","      self.index2word[self.num_words] = word\n","      self.num_words +=1\n","    else:\n","      # Increase word count if word appears before\n","      self.word2count[word] += 1\n","    \n","  # remove words below count threshold\n","  def trim(self, min_count):\n","    if self.trimmed:\n","      self.trimmed = True\n","    \n","    keep_words = []\n","    \n","    for k, v in self.word2count.items():\n","      if v>=min_count:\n","        keep_words.append(k)\n","    \n","    self.word2index = {}\n","    self.word2count = {}\n","    self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n","    self.num_words = 3\n","    \n","    for word in keep_words:\n","      self.addWord(word)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZN6JeJVVdDsI"},"source":["#### **Data Preprocessing Part 2**"]},{"cell_type":"markdown","metadata":{"id":"8aI-EdENHgoe"},"source":["##### **Arrange into Q-R pairs** \n","Steps:\n","1. Convert  Unicode strings to ASCII using unicodeToAscii. \n","2. Convert all letters to lowercase and trim all non-letter characters except for basic punctuation (normalizeString)\n","3. Filter out sentences with length greater than the MAX_LENGTH threshold (filterPairs)."]},{"cell_type":"code","metadata":{"id":"-MWYloBx_tJo"},"source":["MAX_LENGTH = 15\n","\n","def unicode_to_ascii(s):\n","  return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n","\n","def normalizeString(s):\n","  s = unicode_to_ascii(s.lower().strip())\n","  s  = re.sub(r\"([.!?])\", r\" \\1\", s)\n","  s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n","  s = re.sub(r\"\\s+\", r\" \", s).strip()\n","  return s\n","\n","def readVocs(datafile, corpus_name):\n","  print(\"Reading Lines ...\")\n","  \n","  lines = open(datafile, encoding = 'utf-8').\\\n","      read().strip().split('\\n')\n","  \n","  pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n","  voc = Voc(corpus_name)\n","  return voc, pairs\n","\n","# Returns True if both sentences in a pair 'p' are under the MAX_LENGTH threshold\n","def filterPair(p):\n","  # Input sequences need to preserve the last word for EOS token\n","  if len(p) == 2:\n","    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n","\n","# Filter pairs using filterPair condition\n","def filterPairs(pairs):\n","  return [pair for pair in pairs if filterPair(pair)]\n","\n","# Using the functions defined above, return a populated voc object and pairs list\n","def loadPrepareData(corpus_name, datafile):\n","  print(\"Start preparing training data ...\")\n","  voc, pairs = readVocs(datafile, corpus_name)\n","  print(\"Read {!s} sentence pairs\".format(len(pairs)))\n","\n","  \n","  pairs = filterPairs(pairs)\n","\n","  print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n","  print(\"Counting words...\")\n","  for pair in pairs:\n","      voc.addSentences(pair[0])\n","      voc.addSentences(pair[1])\n","  print(\"Counted words:\", voc.num_words)\n","  return voc, pairs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vFUMU1T5WdNl"},"source":["# Load/Assemble voc and pairs\n","corpus_name = \"southpark_corpus\"\n","new_path = os.path.join(corpus_name, \"formatted_southpark_lines_v2.txt\")\n","datafile = new_path\n","voc, pairs = loadPrepareData(corpus_name, datafile)\n","\n","# Print some pairs to validate\n","print(\"\\npairs:\")\n","for pair in pairs[:10]:\n","    print(pair)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gz8BfMGqWjiS"},"source":["#### **Trim sentences**"]},{"cell_type":"code","metadata":{"id":"c3Tc_4MMm_Qj","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"f6c01833-2da4-4e29-d021-23dae62214c7"},"source":["MIN_COUNT = 3    # Minimum word count threshold for trimming\n","\n","def trimRareWords(voc, pairs, MIN_COUNT):\n","    # Trim words used under the MIN_COUNT from the voc\n","    voc.trim(MIN_COUNT)\n","    # Filter out pairs with trimmed words\n","    keep_pairs = []\n","    for pair in pairs:\n","        input_sentence = pair[0]\n","        output_sentence = pair[1]\n","        keep_input = True\n","        keep_output = True\n","        # Check input sentence\n","        for word in input_sentence.split(' '):\n","            if word not in voc.word2index:\n","                keep_input = False\n","                break\n","        # Check output sentence\n","        for word in output_sentence.split(' '):\n","            if word not in voc.word2index:\n","                keep_output = False\n","                break\n","\n","        # Only keep pairs that do not contain trimmed word(s) in their input or output sentence\n","        if keep_input and keep_output:\n","            keep_pairs.append(pair)\n","\n","    print(\"Trimmed from {} pairs to {}, {:.4f} of total\".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n","    return keep_pairs\n","\n","\n","# Trim voc and pairs\n","pairs = trimRareWords(voc, pairs, MIN_COUNT)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Trimmed from 29681 pairs to 21382, 0.7204 of total\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KeHvWiebqi8x"},"source":["# **Data Preparation**"]},{"cell_type":"code","metadata":{"id":"q6d5VnkaWiEq","colab":{"base_uri":"https://localhost:8080/","height":572},"outputId":"f667e628-8a21-47c4-bfbd-ad64af16b262"},"source":["def indexesFromSentence(voc, sentence):\n","    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n","\n","def zeroPadding(l, fillvalue=PAD_token):\n","    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n","\n","def binaryMatrix(l, value=PAD_token):\n","  m = []\n","  for i, seq in enumerate(l):\n","    m.append([])\n","    for token in seq:\n","      if token == PAD_token:\n","        m[i].append(0)\n","      else:\n","        m[i].append(1)\n","  return m\n","\n","# Input Sequence Padding \n","def inputVar(l, voc):\n","  indx_b = [indexesFromSentence(voc, sentence) for sentence in l]\n","  lengths = torch.tensor([len(indexes) for indexes in indx_b])\n","  padList = zeroPadding(indx_b)\n","  padVar = torch.LongTensor(padList)\n","  return padVar, lengths\n","\n","# Output Sequence Padding \n","def outputVar(l, voc):\n","  \"\"\"\"\n","  This function will output:\n","  1. Padded target \n","  2. Padding mask\n","  3. Max target length\n","  \"\"\"\n","  indx_b = [indexesFromSentence(voc, sentence) for sentence in l]\n","  max_target_len = max([len(indexes) for indexes in indx_b])\n","  padList = zeroPadding(indx_b)\n","  mask = binaryMatrix(padList)\n","  mask = torch.ByteTensor(mask)\n","  padVar = torch.LongTensor(padList)\n","  return padVar, mask, max_target_len\n","\n","# Returns all items for a given batch of pairs\n","def batch2TrainData(voc, pair_batch):\n","  pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n","  input_batch, output_batch = [], []\n","  for pair in pair_batch:\n","    input_batch.append(pair[0])\n","    output_batch.append(pair[1])\n","  inp, lengths = inputVar(input_batch, voc)\n","  output, mask, max_target_len = outputVar(output_batch, voc)\n","  return inp, lengths, output, mask, max_target_len\n","\n","\n","# Example for validation\n","small_batch_size = 5\n","batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n","input_variable, lengths, target_variable, mask, max_target_len = batches\n","\n","# Observe output and check to make sure it's correct\n","# DO NOT MOVE ON if tensor lengths are not matching\n","print(\"input_variable:\", input_variable)\n","print(\"lengths:\", lengths)\n","print(\"target_variable:\", target_variable)\n","print(\"mask:\", mask)\n","print(\"max_target_len:\", max_target_len)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["input_variable: tensor([[1063,  155,   28,  119,  114],\n","        [  24,   26,  222,  297,   93],\n","        [2448, 4492,   64,   41,    3],\n","        [   5,  150,   31, 1298,    2],\n","        [  48,   41,    3,   24,    0],\n","        [2517,    9,    2,    2,    0],\n","        [  24,    3,    0,    0,    0],\n","        [   2,    2,    0,    0,    0]])\n","lengths: tensor([8, 8, 6, 6, 4])\n","target_variable: tensor([[  54,   30, 4046,  151,  235],\n","        [ 534,   27,   26,  222,   28],\n","        [ 326,    2,   25,   19,  367],\n","        [ 228,    0,   23,   24,    5],\n","        [  24,    0,  931,    2,   27],\n","        [   2,    0,  648,    0,    2],\n","        [   0,    0,  117,    0,    0],\n","        [   0,    0,   41,    0,    0],\n","        [   0,    0, 4568,    0,    0],\n","        [   0,    0,   27,    0,    0],\n","        [   0,    0,    2,    0,    0]])\n","mask: tensor([[1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1],\n","        [1, 0, 1, 1, 1],\n","        [1, 0, 1, 1, 1],\n","        [1, 0, 1, 0, 1],\n","        [0, 0, 1, 0, 0],\n","        [0, 0, 1, 0, 0],\n","        [0, 0, 1, 0, 0],\n","        [0, 0, 1, 0, 0],\n","        [0, 0, 1, 0, 0]], dtype=torch.uint8)\n","max_target_len: 11\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"N1OEca7yqtkM"},"source":["# Define Model"]},{"cell_type":"markdown","metadata":{"id":"_BdBtwpqq8C_"},"source":["#### Encoder"]},{"cell_type":"code","metadata":{"id":"lJdZABKMqvKN"},"source":["class EncoderRNN(nn.Module):\n","  def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n","    super(EncoderRNN, self).__init__()\n","    self.n_layers = n_layers\n","    self.hidden_size = hidden_size\n","    self.embedding = embedding\n","    \n","    # Initialize GRU\n","    self.gru = nn.GRU(hidden_size, \n","                      hidden_size, \n","                      n_layers,\n","                      dropout=(0 if n_layers == 1 else dropout), \n","                      bidirectional=True)\n","\n","  def forward(self, input_seq, input_lengths, hidden=None):\n","    # Convert word indexes to embeddings\n","    embedded = self.embedding(input_seq)\n","    \n","    # Pack padded batch of sequences for RNN module\n","    packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n","    # Forward pass through GRU\n","    outputs, hidden = self.gru(packed, hidden)\n","    # Unpack padding\n","    outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n","    # Sum bidirectional GRU outputs\n","    outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n","    # Return output and final hidden state\n","    return outputs, hidden"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kkBdXCVwq9ch"},"source":["#### Attention Mechanism"]},{"cell_type":"code","metadata":{"id":"8e-EhODjq6XJ"},"source":["# Luong attention layer\n","class Attn(torch.nn.Module):\n","    def __init__(self, method, hidden_size):\n","        super(Attn, self).__init__()\n","        self.method = method\n","        self.hidden_size = hidden_size\n","        if self.method == 'general':\n","            self.attn = torch.nn.Linear(self.hidden_size, hidden_size)\n","        elif self.method == 'concat':\n","            self.attn = torch.nn.Linear(self.hidden_size * 2, hidden_size)\n","            self.v = torch.nn.Parameter(torch.FloatTensor(hidden_size))\n","\n","    def dot_score(self, hidden, encoder_output):\n","        return torch.sum(hidden * encoder_output, dim=2)\n","\n","    def general_score(self, hidden, encoder_output):\n","        energy = self.attn(encoder_output)\n","        return torch.sum(hidden * energy, dim=2)\n","\n","    def concat_score(self, hidden, encoder_output):\n","        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n","        return torch.sum(self.v * energy, dim=2)\n","\n","    def forward(self, hidden, encoder_outputs):\n","        # Calculate the attention weights (energies) based on the given method\n","        if self.method == 'general':\n","            attn_energies = self.general_score(hidden, encoder_outputs)\n","        elif self.method == 'concat':\n","            attn_energies = self.concat_score(hidden, encoder_outputs)\n","        elif self.method == 'dot':\n","            attn_energies = self.dot_score(hidden, encoder_outputs)\n","\n","        # Transpose max_length and batch_size dimensions\n","        attn_energies = attn_energies.t()\n","\n","        # Return the softmax normalized probability scores (with added dimension)\n","        return F.softmax(attn_energies, dim=1).unsqueeze(1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s8__7vtIrFEY"},"source":["class LuongAttnDecoderRNN(nn.Module):\n","    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n","        super(LuongAttnDecoderRNN, self).__init__()\n","\n","        # Keep for reference\n","        self.attn_model = attn_model\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.n_layers = n_layers\n","        self.dropout = dropout\n","\n","        # Define layers\n","        self.embedding = embedding\n","        self.embedding_dropout = nn.Dropout(dropout)\n","        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n","        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n","        self.out = nn.Linear(hidden_size, output_size)\n","\n","        self.attn = Attn(attn_model, hidden_size)\n","\n","    def forward(self, input_seq, last_hidden, encoder_outputs):\n","        # Note: we run this one step (word) at a time\n","        # Get embedding of current input word\n","        embedded = self.embedding(input_seq)\n","        embedded = self.embedding_dropout(embedded)\n","        # Forward through unidirectional GRU\n","        rnn_output, hidden = self.gru(embedded, last_hidden)\n","        # Calculate attention weights from the current GRU output\n","        attn_weights = self.attn(rnn_output, encoder_outputs)\n","        # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector\n","        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n","        # Concatenate weighted context vector and GRU output using Luong eq. 5\n","        rnn_output = rnn_output.squeeze(0)\n","        context = context.squeeze(1) \n","        concat_input = torch.cat((rnn_output, context), 1)\n","        concat_output = torch.tanh(self.concat(concat_input))\n","        # Predict next word using Luong eq. 6\n","        output = self.out(concat_output)\n","        output = F.softmax(output, dim=1)\n","        # Return output and final hidden state\n","        return output, hidden"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Lz6vijMjrGiC"},"source":["### Masked loss\n","\n","Since we are dealing with batches of padded sequences, we cannot simply consider all elements of the tensor when calculating loss. We define maskNLLLoss to calculate our loss based on our decoder's output tensor, the target tensor, and a binary mask tensor describing the padding of the target tensor. This loss function calculates the average negative log likelihood of the elements that correspond to a 1 in the mask tensor."]},{"cell_type":"code","metadata":{"id":"N4JxMFzUrJut"},"source":["def maskNLLLoss(inp, target, mask):\n","    nTotal = mask.sum()\n","    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)))\n","    loss = crossEntropy.masked_select(mask).mean()\n","    loss = loss.to(device)\n","    return loss, nTotal.item()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2SIVUsnvrPvp"},"source":["### Single training iteration\n","The train function contains the algorithm for a single training iteration (a single batch of inputs).\n","\n","We will use a couple of clever tricks to aid in convergence:\n","\n","The first trick is using teacher forcing. This means that at some probability, set by teacher_forcing_ratio, we use the current target word as the decoder's next input rather than using the decoder's current guess. This technique acts as training wheels for the decoder, aiding in more efficient training. However, teacher forcing can lead to model instability during inference, as the decoder may not have a sufficient chance to truly craft its own output sequences during training. Thus, we must be mindful of how we are setting the teacher_forcing_ratio, and not be fooled by fast convergence.\n","The second trick that we implement is gradient clipping. This is a commonly used technique for countering the \"exploding gradient\" problem. In essence, by clipping or thresholding gradients to a maximum value, we prevent the gradients from growing exponentially and either overflow (NaN), or overshoot steep cliffs in the cost function."]},{"cell_type":"code","metadata":{"id":"NO0AEPkPrQH9"},"source":["def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,\n","          encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=MAX_LENGTH):\n","\n","    # Zero gradients\n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","\n","    # Set device options\n","    input_variable = input_variable.to(device)\n","    lengths = lengths.to(device)\n","    target_variable = target_variable.to(device)\n","    mask = mask.to(device)\n","\n","    # Initialize variables\n","    loss = 0\n","    print_losses = []\n","    n_totals = 0\n","\n","    # Forward pass through encoder\n","    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n","\n","    # Create initial decoder input (start with SOS tokens for each sentence)\n","    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n","    decoder_input = decoder_input.to(device)\n","\n","    # Set initial decoder hidden state to the encoder's final hidden state\n","    decoder_hidden = encoder_hidden[:decoder.n_layers]\n","\n","    # Determine if we are using teacher forcing this iteration\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n","\n","    # Forward batch of sequences through decoder one time step at a time\n","    if use_teacher_forcing:\n","        for t in range(max_target_len):\n","            decoder_output, decoder_hidden = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs\n","            )\n","            # Teacher forcing: next input is current target\n","            decoder_input = target_variable[t].view(1, -1)\n","            # Calculate and accumulate loss\n","            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n","            loss += mask_loss\n","            print_losses.append(mask_loss.item() * nTotal)\n","            n_totals += nTotal\n","    else:\n","        for t in range(max_target_len):\n","            decoder_output, decoder_hidden = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs\n","            )\n","            # No teacher forcing: next input is decoder's own current output\n","            _, topi = decoder_output.topk(1)\n","            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n","            decoder_input = decoder_input.to(device)\n","            # Calculate and accumulate loss\n","            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n","            loss += mask_loss\n","            print_losses.append(mask_loss.item() * nTotal)\n","            n_totals += nTotal\n","\n","    # Perform backpropatation\n","    loss.backward()\n","\n","    # Clip gradients: gradients are modified in place\n","    _ = torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n","    _ = torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n","\n","    # Adjust model weights\n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","\n","    return sum(print_losses) / n_totals"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NmG1PwCirce0"},"source":["### Training iterations\n","It is finally time to tie the full training procedure together with the data. The trainIters function is responsible for running n_iterations of training given the passed models, optimizers, data, etc. This function is quite self explanatory, as we have done the heavy lifting with the train function.\n","\n","One thing to note is that when we save our model, we save a tarball containing the encoder and decoder state_dicts (parameters), the optimizers' state_dicts, the loss, the iteration, etc. Saving the model in this way will give us the ultimate flexibility with the checkpoint. After loading a checkpoint, we will be able to use the model parameters to run inference, or we can continue training right where we left off."]},{"cell_type":"code","metadata":{"id":"WIVlWxHdrckU"},"source":["def trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, \n","               embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, \n","               print_every, save_every, clip, corpus_name, loadFilename):\n","\n","    # Load batches for each iteration\n","    training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n","                      for _ in range(n_iteration)]\n","\n","    # Initializations\n","    print('Initializing ...')\n","    start_iteration = 1\n","    print_loss = 0\n","    if loadFilename:\n","        start_iteration = checkpoint['iteration'] + 1\n","\n","    # Training loop\n","    print(\"Training...\")\n","    for iteration in range(start_iteration, n_iteration + 1):\n","        training_batch = training_batches[iteration - 1]\n","        # Extract fields from batch\n","        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n","\n","        # Run a training iteration with batch\n","        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n","                     decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n","        print_loss += loss\n","\n","        # Print progress\n","        if iteration % print_every == 0:\n","            print_loss_avg = print_loss / print_every\n","            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n","            print_loss = 0\n","\n","        # Save checkpoint\n","        if (iteration % save_every == 0):\n","            directory = os.path.join(save_dir, model_name, corpus_name, '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n","            if not os.path.exists(directory):\n","                os.makedirs(directory)\n","            torch.save({\n","                'iteration': iteration,\n","                'en': encoder.state_dict(),\n","                'de': decoder.state_dict(),\n","                'en_opt': encoder_optimizer.state_dict(),\n","                'de_opt': decoder_optimizer.state_dict(),\n","                'loss': loss,\n","                'voc_dict': voc.__dict__,\n","                'embedding': embedding.state_dict()\n","            }, os.path.join(directory, '{}_{}.tar'.format(iteration, 'checkpoint')))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mO4U0S5ostET"},"source":["### Define Evaluation\n","After training a model, we want to be able to talk to the bot ourselves. First, we must define how we want the model to decode the encoded input.\n","\n","#### Greedy decoding\n","Greedy decoding is the decoding method that we use during training when we are NOT using teacher forcing. In other words, for each time step, we simply choose the word from decoder_output with the highest softmax value. This decoding method is optimal on a single time-step level.\n","\n","To facilite the greedy decoding operation, we define a GreedySearchDecoder class. When run, an object of this class takes an input sequence (input_seq) of shape (input_seq length, 1), a scalar input length (input_length) tensor, and a max_length to bound the response sentence length. The input sentence is evaluated using the following computational graph:\n","\n","**Computation Graph:**\n","\n","1. Forward input through encoder model.\n","2. Prepare encoder's final hidden layer to be first hidden input to the decoder.\n","3. Initialize decoder's first input as SOS_token.\n","4. Initialize tensors to append decoded words to.\n","5. Iteratively decode one word token at a time:\n","    - a) Forward pass through decoder.\n","    - b) Obtain most likely word token and its softmax score.\n","    - c) Record token and score.\n","    - d) Prepare current token to be next decoder input.\n","6. Return collections of word tokens and scores."]},{"cell_type":"code","metadata":{"id":"IOzIK2JpstMb"},"source":["class GreedySearchDecoder(nn.Module):\n","    def __init__(self, encoder, decoder):\n","        super(GreedySearchDecoder, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def forward(self, input_seq, input_length, max_length):\n","        # Forward input through encoder model\n","        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n","        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n","        decoder_hidden = encoder_hidden[:decoder.n_layers]\n","        # Initialize decoder input with SOS_token\n","        decoder_input = torch.LongTensor([[SOS_token]])\n","        decoder_input = decoder_input.to(device)\n","        # Initialize tensors to append decoded words to\n","        all_tokens = torch.zeros([0], device=self._device, dtype=torch.long)\n","        all_scores = torch.zeros([0], device=self._device)\n","        # Iteratively decode one word token at a time\n","        for _ in range(max_length):\n","            # Forward pass through decoder\n","            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n","            # Obtain most likely word token and its softmax score\n","            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n","            # Record token and score\n","            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n","            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n","            # Prepare current token to be next decoder input (add a dimension)\n","            decoder_input = torch.unsqueeze(decoder_input, 0)\n","        # Return collections of word tokens and scores\n","        return all_tokens, all_scores"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sC1eGwNLtHbD"},"source":["### Evaluate my text\n","Now that we have our decoding method defined, we can write functions for evaluating a string input sentence. The evaluate function manages the low-level process of handling the input sentence. We first format the sentence as an input batch of word indexes with batch_size==1. We do this by converting the words of the sentence to their corresponding indexes, and transposing the dimensions to prepare the tensor for our models. Concurrently, we create our lengths tensor which contains the length of our input sentence. In this case, lengths is scalar because we are only evaluating one sentence at a time (batch_size==1). Next, we obtain the decoded response sentence tensor using our GreedySearchDecoder object (searcher). Finally, we convert the response's indexes to words and return the list of decoded words.\n","\n","evaluateInput acts as the user interface for our chatbot. When called, an input text field will spawn in which we can enter our query sentence. After typing our input sentence and pressing Enter, our text is normalized in the same way as our training data, and is ultimately fed to the evaluate function to obtain a decoded output sentence. We loop this process, so we can keep chatting with our bot until we enter either \"q\" or \"quit\".\n","\n","Finally, if a sentence is entered that contains a word that is not in the vocabulary, we handle this gracefully by printing an error message and prompting the user to enter another sentence."]},{"cell_type":"code","metadata":{"id":"eIA3cre-tKKP"},"source":["def evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH):\n","    ### Format input sentence as a batch\n","    # words -> indexes\n","    indexes_batch = [indexesFromSentence(voc, sentence)]\n","    # Create lengths tensor\n","    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n","    # Transpose dimensions of batch to match models' expectations\n","    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n","    # Use appropriate device\n","    input_batch = input_batch.to(device)\n","    lengths = lengths.to(device)\n","    # Decode sentence with searcher\n","    tokens, scores = searcher(input_batch, lengths, max_length)\n","    # indexes -> words\n","    decoded_words = [voc.index2word[token.item()] for token in tokens]\n","    return decoded_words\n","\n","\n","def evaluateInput(encoder, decoder, searcher, voc):\n","    input_sentence = ''\n","    while(1):\n","        try:\n","            # Get input sentence\n","            input_sentence = input('> ')\n","            # Check if it is quit case\n","            if input_sentence == 'q' or input_sentence == 'quit': break\n","            # Normalize sentence\n","            input_sentence = normalizeString(input_sentence)\n","            # Evaluate sentence\n","            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n","            # Format and print response sentence\n","            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n","            print('Bot:', ' '.join(output_words))\n","    \n","        except KeyError:\n","            # print(\"Error: Encountered unknown word.\")\n","            print(\"I don't know!\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OFWd2s4wtP2y"},"source":["# Run Model"]},{"cell_type":"code","metadata":{"id":"2j7KblLotPTo","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"e19dad30-fb77-404b-d47d-6fb2d787c945"},"source":["model_name = 'cb_model_2'\n","attn_model = 'dot'\n","#attn_model = 'general'\n","#attn_model = 'concat'\n","hidden_size = 500\n","encoder_n_layers = 2\n","decoder_n_layers = 2\n","dropout = 0.1\n","batch_size = 64\n","\n","# Set checkpoint to load from; set to None if starting from scratch\n","loadFilename = None\n","checkpoint_iter = 4000\n","# loadFilename = os.path.join(corpus_name, \n","#                             '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size) +'{}_checkpoint.tar'.format(checkpoint_iter))\n","\n","\n","# Load model if a loadFilename is provided\n","if loadFilename:\n","    # If loading on same machine the model was trained on\n","    checkpoint = torch.load(loadFilename)\n","    # If loading a model trained on GPU to CPU\n","    #checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n","    encoder_sd = checkpoint['en']\n","    decoder_sd = checkpoint['de']\n","    encoder_optimizer_sd = checkpoint['en_opt']\n","    decoder_optimizer_sd = checkpoint['de_opt']\n","    embedding_sd = checkpoint['embedding']\n","    voc.__dict__ = checkpoint['voc_dict']\n","    \n","\n","print('Building encoder and decoder ...')\n","# Initialize word embeddings\n","embedding = nn.Embedding(voc.num_words, hidden_size)\n","\n","if loadFilename:\n","    embedding.load_state_dict(embedding_sd)\n","# Initialize encoder & decoder models\n","encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n","decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n","if loadFilename:\n","    encoder.load_state_dict(encoder_sd)\n","    decoder.load_state_dict(decoder_sd)\n","\n","USE_CUDA = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n","# Use appropriate device\n","encoder = encoder.to(device)\n","decoder = decoder.to(device)\n","print('Models built and ready to go!')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Building encoder and decoder ...\n","Models built and ready to go!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"H_NNEeD2wJVz"},"source":["### Run Training\n","Run the following block if you want to train the model.\n","\n","First we set training parameters, then we initialize our optimizers, and finally we call the trainIters function to run our training iterations."]},{"cell_type":"code","metadata":{"id":"2MPrx5uYwJeR"},"source":["# Configure training/optimization\n","clip = 50.0\n","teacher_forcing_ratio = 1.0\n","learning_rate = 0.0001\n","decoder_learning_ratio = 5.0\n","n_iteration = 10000\n","print_every = 1\n","save_every = 500\n","\n","# Ensure dropout layers are in train mode\n","encoder.train()\n","decoder.train()\n","\n","# Initialize optimizers\n","print('Building optimizers ...')\n","encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n","decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n","if loadFilename:\n","    encoder_optimizer.load_state_dict(encoder_optimizer_sd)\n","    decoder_optimizer.load_state_dict(decoder_optimizer_sd)\n","\n","save_dir = \"new_training\"\n","# Run training iterations\n","print(\"Starting Training!\")\n","trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, \n","           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, \n","           print_every, save_every, clip, corpus_name, loadFilename)"],"execution_count":null,"outputs":[]}]}